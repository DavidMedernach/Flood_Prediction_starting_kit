{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import src.baseline_model02 as bm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second model computation\n",
    "\n",
    "Loading of the data path, *nb_train_minicube*, *nb_test_minicube* and *nb_val_minicube*, are used to limit the number of \"mini data cube\" used in train/test/val and therefore reduce the computational cost of the trainning and hyper parameters exploration. When *compute_full_test_set* is activated the full test set is created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_model_generator_test = bm.BaseLineModel(\n",
    "    \"localdata/smallbox/label/label_\",\n",
    "    dynamic_features_path = \"localdata/Model1_score_ERA5_Rez_v2.nc\",\n",
    "    static_features_root_path = \"localdata/smallbox/static/static_\",\n",
    "    dynamic_features_FR_path = \"localdata/Model1_Score_Full_Rez_v2.nc\",\n",
    "    inf_dynamic_features_FR_path = \"localdata/Model1_Score_Full_Rez_inf.nc\",\n",
    "    static_features_FR_path = \"localdata/static_Full_Rez.nc\",\n",
    "    labels_ERA5_path = \"localdata/final_label_Full_ERA5.nc\",\n",
    "    labels_FR_path = \"localdata/final_label_Full_Rez.nc\",\n",
    "    nb_train_minicube = 80, #Those values are very small for good performance you will need more datacubes\n",
    "    nb_test_minicube = 80, #Those values are very small for apropriate test you will need more datacubes\n",
    "    nb_val_minicube = 20,\n",
    "    min_score_model1 = 0.2,\n",
    "    name=\"Baseline_Model_2_Small_20_02\",\n",
    "    seed=1\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparation of the train / test / val dataset\n",
    "\n",
    "This process is quite long, the vectorised train / test / val can be saved to gain time when training several models on the same datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_model_generator_test.prepare_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The vectorised Full train test (all France data on the define time slices for test train might be quite long to process).\n",
    "Furthermore the *Full test set*, by nature, is fixed, so we process the vectorised *Full Test Set* independently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training of a model \n",
    "\n",
    "Trainning a Random Forest with all features, 150 trees and depth 8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_model_generator_test.load_indiv([True, #soilgrid_bdod\n",
    "                                          True, #soilgrid_cfvo\n",
    "                                          True, #soilgrid_silt\n",
    "                                          True, #soilgrid_clay\n",
    "                                          True, #soilgrid_sand\n",
    "                                          True, #depth_to_bedrock\n",
    "                                          True, #altitude\n",
    "                                          True, #aspect\n",
    "                                          True, #slope\n",
    "                                          True, #water_density\n",
    "                                          True, #watershed\n",
    "                                          True, #topological_catchment_areas\n",
    "                                          True, #dist_sea\n",
    "                                          True, #dist_riv\n",
    "                                          True, #M1_score\n",
    "                                          150, \n",
    "                                          8], \n",
    "                                     False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving and loading model\n",
    "\n",
    "Vectorised test/train/validation dataset and trainned models are saved (the Full test saved is saved independently)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_model_generator_test.save_to_disk()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading of previously saved models / vectorised dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "baseline_model_generator_test = baseline_model_generator_test.load_from_disk(\"Baseline_Model_2_Small_20_02\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper parameters search\n",
    "\n",
    "Using Genetic Algorithms for hyper parameters optimisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline_model_generator_test.GA_optimisation(ngen = 40, pop = 60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Analysis\n",
    "\n",
    "### Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_model_generator_test.print_feature_importance()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing of the full test data\n",
    "\n",
    "Loading of the Full Test Dataset from disk.\n",
    "This process is quite slow when you have done it one time you d'ont need to do it again as long as you don't change your first model outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_model_generator_test.prepare_data(compute_full_test_set=True) #This will take a while, only do it one time\n",
    "baseline_model_generator_test.save_full_test_to_disk(name=\"Full\") #Saving the results to disk\n",
    "baseline_model_generator_test.load_full_test_from_disk(name=\"Full\") #Loading the results from disk, start from here if you already computed the full test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geographical results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Prediction score Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### False Positive, True Positive, False Negative Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_model_generator_test.load_FullRez()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_model_generator_test.print_TNTPFN(save_path=\"graph/Model2/TNTPFN/\", thresholdM1=0.5, thresholdM2=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_model_generator_test.print_proba(save_path=\"graph/Model2/Proba/\", thresholdM1=0.5, thresholdM2=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AUC Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_model_generator_test.auc_graph(\"Full_Test\", \"\", [0.01,0.05,0.1,0.15, 0.2,0.3, 0.5, 0.9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_model_generator_test.process_AUC_metrics(filter=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_model_generator_test.process_prediction_metrics(filter=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computation of predictions for codabench\n",
    "\n",
    "#### Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_model_generator_test.load_InfRez()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Printing of the prediction map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_model_generator_test.print_proba_inf(save_path=\"graph/Model2/inference/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_model_generator_test.save_full_pred()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading of the previously computed predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = xr.open_dataset(\"localdata/Model2_Score_Full_Rez_inf.nc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conversion to vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_xarray_to_vector(data: xr.DataArray):\n",
    "    xry = data.M2_score.values\n",
    "    vectors = xry.reshape(xry.shape[0], xry.shape[1]*xry.shape[2])\n",
    "    vector = vectors.flatten()\n",
    "    final_label_Full_Rez = xr.open_dataset(\"localdata/final_label_Full_Rez.nc\")\n",
    "    ws = final_label_Full_Rez.sel(time=\"2002-08-04\")[\"__xarray_dataarray_variable__\"].values\n",
    "    mask = np.invert(np.isnan(np.where(ws == -1, np.nan, ws)))\n",
    "    mask = np.repeat(mask, xry.shape[0])\n",
    "    return vector[mask].astype('float16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = from_xarray_to_vector(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(out).to_csv(\"localdata/pred.csv\")\n",
    "shutil.make_archive(\"localdata/pred.csv\", 'zip', \"localdata\",\"pred.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clean_geo_env_dav_5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
